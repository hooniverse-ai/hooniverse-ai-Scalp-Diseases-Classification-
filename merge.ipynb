{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b418e7b6",
   "metadata": {},
   "source": [
    "# 필요 라이브러리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5e4afa74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %% 표준 라이브러리\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "from datetime import datetime, timedelta\n",
    "# %% 수치·데이터 처리\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "# %% 시각화\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image, ImageEnhance, ImageFilter\n",
    "import cv2\n",
    "# %% PyTorch 및 관련\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions import Normal\n",
    "from torch.utils.data import DataLoader, Dataset, Subset, WeightedRandomSampler\n",
    "from torch.optim.lr_scheduler import StepLR, OneCycleLR, ReduceLROnPlateau\n",
    "from torch.cuda.amp import GradScaler\n",
    "from torch.amp import autocast\n",
    "\n",
    "\n",
    "# %% torchvision\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.models import efficientnet_b3, EfficientNet_B3_Weights, efficientnet_b0, EfficientNet_B0_Weights\n",
    "\n",
    "\n",
    "from transformers import CLIPProcessor, CLIPModel\n",
    "\n",
    "# %% 유틸리티\n",
    "from torchinfo import summary\n",
    "from tqdm import tqdm\n",
    "\n",
    "# %% 데이터 분할\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "\n",
    "plt.rcParams['font.family'] = 'Malgun Gothic'  # Windows의 경우, 한글 지원 폰트로 설정\n",
    "plt.rcParams['axes.unicode_minus'] = False       # 음수 기호가 깨지지 않도록 설정\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a500ddab",
   "metadata": {},
   "source": [
    "# 파라미터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "510ab86f",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = (224, 224)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d45e0c7a",
   "metadata": {},
   "source": [
    "# 모델정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e787ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "질환 예측 시작...\n",
      "========== 두피 질환별 예측 결과 ==========\n",
      "● 미세각질: 경증 (77.32%)\n",
      "● 피지과다: 중증 (43.49%)\n",
      "● 모낭사이홍반: 경증 (84.21%)\n",
      "● 모낭농포: 경증 (85.46%)\n",
      "● 비듬: 경증 (86.81%)\n",
      "● 탈모: 경증 (69.89%)\n",
      "==========================================\n"
     ]
    }
   ],
   "source": [
    "# 6개 질환 모델과 전처리 함수\n",
    "pizi_model_path = r'C:\\Users\\user1\\Desktop\\Code\\Scalp_Disease_Classifier\\result\\model\\compressed\\biddem_B0_compressed.pt'\n",
    "# pizi_model_path = r'C:\\Users\\user1\\Desktop\\Code\\Scalp_Disease_Classifier\\result\\model\\compressed\\biddem_compressed.pt' # b3\n",
    "\n",
    "talmo_model_path = r'C:\\Users\\user1\\Desktop\\Code\\Scalp_Disease_Classifier\\result\\model\\compressed\\talmo_B0_compressed.pt'\n",
    "mosa_model_path = r'C:\\Users\\user1\\Desktop\\Code\\Scalp_Disease_Classifier\\result\\model\\compressed\\mosa_B0_compressed.pt'\n",
    "mono_model_path = r'C:\\Users\\user1\\Desktop\\Code\\Scalp_Disease_Classifier\\result\\model\\compressed\\mono_B0_compressed.pt'\n",
    "# mono_model_path = r'C:\\Users\\user1\\Desktop\\Code\\Scalp_Disease_Classifier\\result\\model\\compressed\\mono_compressed.pt' # b3\n",
    "mise_model_path = r'C:\\Users\\user1\\Desktop\\Code\\Scalp_Disease_Classifier\\result\\model\\compressed\\mise_B0_compressed.pt'\n",
    "biddem_model_path = r'C:\\Users\\user1\\Desktop\\Code\\Scalp_Disease_Classifier\\result\\model\\compressed\\biddem_B0_compressed.pt'\n",
    "\n",
    "def load_model(model_path):\n",
    "    model = efficientnet_b0()  \n",
    "    in_features = model.classifier[1].in_features\n",
    "    model.classifier[1] = nn.Sequential(nn.Linear(in_features, 512),\n",
    "                                        nn.BatchNorm1d(512),       # 배치 정규화 추가\n",
    "                                        nn.ReLU(),                 # 혹은 nn.ReLU()\n",
    "                                        nn.Linear(512, 3))         # 최종 클래스 수\n",
    "    state_dict = torch.load(model_path)\n",
    "    model.load_state_dict(state_dict)\n",
    "    model = model.to(DEVICE)\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "def load_model_b3(model_path):\n",
    "    model = efficientnet_b3()  \n",
    "    in_features = model.classifier[1].in_features\n",
    "    model.classifier[1] = nn.Sequential(nn.Linear(in_features, 512),\n",
    "                                        nn.BatchNorm1d(512),       # 배치 정규화 추가\n",
    "                                        nn.ReLU(),                 # 혹은 nn.ReLU()\n",
    "                                        nn.Linear(512, 3))         # 최종 클래스 수\n",
    "    state_dict = torch.load(model_path)\n",
    "    model.load_state_dict(state_dict)\n",
    "    model = model.to(DEVICE)\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "\n",
    "pizi_model    = load_model(pizi_model_path)\n",
    "talmo_model   = load_model(talmo_model_path)\n",
    "mosa_model    = load_model(mosa_model_path)\n",
    "mono_model    = load_model(mono_model_path)\n",
    "mise_model    = load_model(mise_model_path)\n",
    "biddem_model  = load_model(biddem_model_path)\n",
    "\n",
    "disease_models = [\n",
    "    mise_model, pizi_model, mosa_model, mono_model, biddem_model, talmo_model  # 이미 load된 상태 (eval)\n",
    "]\n",
    "\n",
    "# 미세각질\n",
    "class UnsharpMaskTransform(object):\n",
    "    def __call__(self, img):\n",
    "        return img.filter(ImageFilter.UnsharpMask(radius=2, percent=150, threshold=3))\n",
    "\n",
    "class LaplacianEnhanceTransform(object):\n",
    "    def __call__(self, img):\n",
    "        img_np = np.array(img)\n",
    "        gray = cv2.cvtColor(img_np, cv2.COLOR_RGB2GRAY)\n",
    "        lap = cv2.Laplacian(gray, cv2.CV_64F, ksize=3)\n",
    "        lap = np.clip(lap, 0, 255).astype(np.uint8)\n",
    "        lap_rgb = cv2.cvtColor(lap, cv2.COLOR_GRAY2RGB)\n",
    "        # 원본과 Laplacian 결과를 합성\n",
    "        enhanced = cv2.addWeighted(img_np, 0.8, lap_rgb, 0.5, 0)\n",
    "        return Image.fromarray(enhanced)\n",
    "\n",
    "mise_preprocess = transforms.Compose([\n",
    "    UnsharpMaskTransform(),\n",
    "    LaplacianEnhanceTransform(),\n",
    "    transforms.Resize(IMAGE_SIZE),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# 피지과다\n",
    "class RemoveReflection(object):\n",
    "    def __call__(self, img):\n",
    "        return img.filter(ImageFilter.MedianFilter(size=3))\n",
    "\n",
    "class EnhanceContrastSebaceous(object):\n",
    "    def __call__(self, img):\n",
    "        enhancer = ImageEnhance.Contrast(img)\n",
    "        return enhancer.enhance(1.5)\n",
    "\n",
    "pizi_preprocess = transforms.Compose([\n",
    "    RemoveReflection(),\n",
    "    EnhanceContrastSebaceous(),\n",
    "    transforms.Resize((300, 300)),  # 피지과다 이미지 크기 조정\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# 모낭사이홍반\n",
    "class ErythemaRednessEnhanceTransform:\n",
    "    def __init__(self, apply_mask: bool=False):\n",
    "        # a* 채널 CLAHE\n",
    "        self.clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(4,4))\n",
    "        self.apply_mask = apply_mask\n",
    "\n",
    "    def __call__(self, img: Image.Image) -> Image.Image:\n",
    "        # 1) RGB → LAB → a* 채널만 CLAHE\n",
    "        img_np    = np.array(img)\n",
    "        lab       = cv2.cvtColor(img_np, cv2.COLOR_RGB2LAB)\n",
    "        l, a, b   = cv2.split(lab)\n",
    "        a_clahe   = self.clahe.apply(a)\n",
    "        lab_clahe = cv2.merge((l, a_clahe, b))\n",
    "        img_clahe = cv2.cvtColor(lab_clahe, cv2.COLOR_LAB2RGB)\n",
    "\n",
    "        if self.apply_mask:\n",
    "            # 2) HSV 마스크로 붉은 영역 분리\n",
    "            hsv    = cv2.cvtColor(img_clahe, cv2.COLOR_RGB2HSV)\n",
    "            lower1 = (0,   50, 50); upper1 = (15, 255,255)\n",
    "            lower2 = (160, 50, 50); upper2 = (180,255,255)\n",
    "            m1     = cv2.inRange(hsv, lower1, upper1)\n",
    "            m2     = cv2.inRange(hsv, lower2, upper2)\n",
    "            mask   = cv2.bitwise_or(m1, m2)\n",
    "\n",
    "            # 3) 배경은 회색조로 변환\n",
    "            gray     = cv2.cvtColor(img_clahe, cv2.COLOR_RGB2GRAY)\n",
    "            gray_rgb = cv2.cvtColor(gray, cv2.COLOR_GRAY2RGB)\n",
    "\n",
    "            # 4) 마스크 영역만 컬러, 나머지는 gray\n",
    "            mask_bool = mask.astype(bool)[..., None]\n",
    "            result    = np.where(mask_bool, img_clahe, gray_rgb)\n",
    "            return Image.fromarray(result.astype(np.uint8))\n",
    "\n",
    "        # apply_mask=False: CLAHE 처리된 컬러만 반환\n",
    "        return Image.fromarray(img_clahe)\n",
    "    \n",
    "mosa_preprocess = transforms.Compose([\n",
    "    ErythemaRednessEnhanceTransform(apply_mask=True),\n",
    "    transforms.Resize(IMAGE_SIZE),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# 모낭농포\n",
    "class EmphasizeRedTransform(object):\n",
    "    \"\"\"LAB a* 채널(JET colormap)로 염증(적색) 강조\"\"\"\n",
    "    def __call__(self, img):\n",
    "        img_np = np.array(img)\n",
    "        lab = cv2.cvtColor(img_np, cv2.COLOR_RGB2LAB)\n",
    "        l, a, b = cv2.split(lab)\n",
    "        # a* 채널 정규화 후 pseudocolor\n",
    "        a_norm = cv2.normalize(a, None, 0, 255, cv2.NORM_MINMAX)\n",
    "        a_color = cv2.applyColorMap(a_norm, cv2.COLORMAP_JET)\n",
    "        # cv2는 BGR 반환이므로 RGB 변환 필요\n",
    "        a_color_rgb = cv2.cvtColor(a_color, cv2.COLOR_BGR2RGB)\n",
    "        return Image.fromarray(a_color_rgb)\n",
    "    \n",
    "mono_preprocess = transforms.Compose([\n",
    "    EmphasizeRedTransform(),             # 염증 강조 (a* pseudocolor)\n",
    "    transforms.Resize((300, 300)),\n",
    "    transforms.ToTensor(),\n",
    "    # 시각화용이라면 Normalize 생략, 모델 추론용이면 Normalize 적용\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# 비듬\n",
    "class CLAHETransform(object):\n",
    "    def __init__(self, clip_limit=0.4, grid_size=(4,4)):\n",
    "        self.clahe = cv2.createCLAHE(clipLimit=clip_limit, tileGridSize=grid_size)\n",
    "\n",
    "    def __call__(self, img):\n",
    "        img_np = np.array(img)\n",
    "        lab = cv2.cvtColor(img_np, cv2.COLOR_RGB2LAB)\n",
    "        l, a, b = cv2.split(lab)\n",
    "        l_clahe = self.clahe.apply(l)\n",
    "        lab_clahe = cv2.merge((l_clahe, a, b))\n",
    "        img_rgb = cv2.cvtColor(lab_clahe, cv2.COLOR_LAB2RGB)\n",
    "        return Image.fromarray(img_rgb)\n",
    "\n",
    "# Sharpen transform\n",
    "class SharpenTransform(object):\n",
    "    def __call__(self, img):\n",
    "        return img.filter(ImageFilter.UnsharpMask(radius=2, percent=150, threshold=3))\n",
    "    \n",
    "biddem_preprocess = transforms.Compose([\n",
    "    CLAHETransform(clip_limit=0.4, grid_size=(4,4)),             # 염증 강조 (a* pseudocolor)\n",
    "    SharpenTransform(),\n",
    "    transforms.Resize(IMAGE_SIZE),\n",
    "    transforms.ToTensor(),\n",
    "    # 시각화용이라면 Normalize 생략, 모델 추론용이면 Normalize 적용\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# 탈모\n",
    "class AlopeciaHLFTransform(object):\n",
    "    def __init__(self, grid_size=8):\n",
    "        self.grid_size = grid_size\n",
    "\n",
    "    def __call__(self, img):\n",
    "        # 1. CLAHE (contrast enhancement)\n",
    "        img_np = np.array(img)\n",
    "        lab = cv2.cvtColor(img_np, cv2.COLOR_RGB2LAB)\n",
    "        l, a, b = cv2.split(lab)\n",
    "        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(4,4))\n",
    "        l_clahe = clahe.apply(l)\n",
    "        lab_clahe = cv2.merge((l_clahe, a, b))\n",
    "        img_clahe = cv2.cvtColor(lab_clahe, cv2.COLOR_LAB2RGB)\n",
    "\n",
    "        # 2. Sharpening\n",
    "        img_sharp = cv2.addWeighted(img_clahe, 1.5, cv2.GaussianBlur(img_clahe, (0,0), 3), -0.5, 0)\n",
    "\n",
    "        return Image.fromarray(img_sharp)\n",
    "    \n",
    "talmo_preprocess = transforms.Compose([\n",
    "    AlopeciaHLFTransform(grid_size=8),\n",
    "    transforms.Resize(IMAGE_SIZE),\n",
    "    transforms.ToTensor(),\n",
    "    # 시각화용이라면 Normalize 생략, 모델 추론용이면 Normalize 적용\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "preprocess_funcs = [\n",
    "    mise_preprocess, pizi_preprocess, mosa_preprocess, mono_preprocess, biddem_preprocess, talmo_preprocess  # 각 질환별 전처리\n",
    "]\n",
    "\n",
    "disease_names = [\"미세각질\", \"피지과다\", \"모낭사이홍반\", \"모낭농포\", \"비듬\", \"탈모\"]\n",
    "\n",
    "# ────────────── 함수 정의 ──────────────\n",
    "\n",
    "# ────────────── 2. 질환별 추론 ──────────────\n",
    "def disease_inference(img_pil, disease_models, preprocess_funcs, disease_names):\n",
    "    \"\"\"\n",
    "    질환별 전처리 & 모델 추론\n",
    "    결과: {질환명: {'pred_class': int, 'probs': np.array}}\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "    for model, preprocess, name in zip(disease_models, preprocess_funcs, disease_names):\n",
    "        tensor = preprocess(img_pil).unsqueeze(0).to(DEVICE)\n",
    "        with torch.no_grad():\n",
    "            out = model(tensor)\n",
    "            probs = torch.softmax(out, dim=1)[0].cpu().numpy()\n",
    "            pred = int(probs.argmax())\n",
    "        results[name] = {\"pred_class\": pred, \"probs\": probs}\n",
    "        torch.cuda.empty_cache()\n",
    "    return results\n",
    "\n",
    "# ────────────── 3. 결과 깔끔하게 출력 ──────────────\n",
    "def pretty_print_disease_result_top1(disease_result, class_labels):\n",
    "    \"\"\"\n",
    "    Top-1 예측 결과를 콘솔에 깔끔히 출력\n",
    "    class_labels: [[클래스명1, ...], ...]\n",
    "    \"\"\"\n",
    "    print(\"========== 두피 질환별 예측 결과 ==========\")\n",
    "    for idx, (disease, res) in enumerate(disease_result.items()):\n",
    "        pred = res[\"pred_class\"]\n",
    "        prob = res[\"probs\"][pred]\n",
    "        name = class_labels[idx][pred]\n",
    "        print(f\"● {disease}: {name} ({prob:.2%})\")\n",
    "    print(\"==========================================\")\n",
    "\n",
    "# ────────────── 6. 메인 파이프라인 ──────────────\n",
    "def main_pipeline(img_path):\n",
    "    img = Image.open(img_path).convert(\"RGB\")\n",
    "    img = img.resize(IMAGE_SIZE)\n",
    "\n",
    "    print(\"질환 예측 시작...\")\n",
    "    res = disease_inference(img, disease_models, preprocess_funcs, disease_names)\n",
    "    pretty_print_disease_result_top1(res, class_labels)\n",
    "    \n",
    "\n",
    "# ────────────── 실행 예시 ──────────────\n",
    "\n",
    "# 클래스 라벨 설정\n",
    "class_labels = [\n",
    "    [\"정상\",\"경증\",\"중증\"],  # 미세각질\n",
    "    [\"정상\",\"경증\",\"중증\"],  # 피지과다\n",
    "    [\"정상\",\"경증\",\"중증\"],  # 모낭사이홍반\n",
    "    [\"정상\",\"경증\",\"중증\"],  # 모낭농포\n",
    "    [\"정상\",\"경증\",\"중증\"],  # 비듬\n",
    "    [\"정상\",\"경증\",\"중증\"],  # 탈모\n",
    "]\n",
    "\n",
    "# 이미지 경로 지정\n",
    "img_path = r\"C:\\Users\\user1\\Desktop\\Code\\Scalp_Disease_Classifier\\data\\pizi_org_3_preprocess\\train\\중증\\0013_A2LEBJJDE00060O_1603257373184_2_TH.jpg\"\n",
    "main_pipeline(img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d4a315",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53869533",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e8ef16d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c775e4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ddd95dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b51caf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pt_py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
